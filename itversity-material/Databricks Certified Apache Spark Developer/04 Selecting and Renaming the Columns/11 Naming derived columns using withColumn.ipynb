{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "874d7cc6-c904-41f4-ab47-8ca13ff56af4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "| id|first_name|   last_name|               email|       phone_numbers|courses|is_customer|amount_paid|customer_from|    last_updated_ts|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "|  1|    Corrie|Van den Oord|cvandenoord0@etsy...|{+1 234 567 8901,...| [1, 2]|       true|    1000.55|   2021-01-15|2021-02-10 01:15:00|\n",
      "|  2|  Nikolaus|     Brewitt|nbrewitt1@dailyma...|{+1 234 567 8923,...|    [3]|       true|      900.0|   2021-02-14|2021-02-18 03:33:00|\n",
      "|  3|    Orelie|      Penney|openney2@vistapri...|{+1 714 512 9752,...| [2, 4]|       true|     850.55|   2021-01-21|2021-03-15 15:16:55|\n",
      "|  4|     Ashby|    Maddocks|  amaddocks3@home.pl|        {null, null}|     []|      false|        NaN|         null|2021-04-10 17:45:30|\n",
      "|  5|      Kurt|        Rome|krome4@shutterfly...|{+1 817 934 7142,...|     []|      false|        NaN|         null|2021-04-02 00:55:18|\n",
      "+---+----------+------------+--------------------+--------------------+-------+-----------+-----------+-------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%run \"./02 Creating Spark Data Frame to Select and Rename Columns.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aa179760-23b0-4d1f-b147-7326e4b87554",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+\n",
      "| id|first_name|   last_name|\n",
      "+---+----------+------------+\n",
      "|  1|    Corrie|Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|\n",
      "|  3|    Orelie|      Penney|\n",
      "|  4|     Ashby|    Maddocks|\n",
      "|  5|      Kurt|        Rome|\n",
      "+---+----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    select('id', 'first_name', 'last_name'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e1389768-cddb-40cb-a9c4-eb20507ba3b4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "* Concat `first_name` and `last_name`. Provide an alias to the derived result as `full_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c112d8a2-322b-40dd-bf87-5330c3b02a68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b45eb4e4-ac5e-44dc-9aa4-4a539aca0357",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           full_name|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Equivalent logic using select\n",
    "users_df. \\\n",
    "    select(\n",
    "        'id', 'first_name', 'last_name',\n",
    "        concat('first_name', lit(', '), 'last_name').alias('full_name')\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "092ae7a3-249a-4f1e-84c7-124f74c9934b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------------------+\n",
      "| id|first_name|   last_name|           full_name|\n",
      "+---+----------+------------+--------------------+\n",
      "|  1|    Corrie|Van den Oord|Corrie, Van den Oord|\n",
      "|  2|  Nikolaus|     Brewitt|   Nikolaus, Brewitt|\n",
      "|  3|    Orelie|      Penney|      Orelie, Penney|\n",
      "|  4|     Ashby|    Maddocks|     Ashby, Maddocks|\n",
      "|  5|      Kurt|        Rome|          Kurt, Rome|\n",
      "+---+----------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    select('id', 'first_name', 'last_name'). \\\n",
    "    withColumn('full_name', concat('first_name', lit(', '), 'last_name')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5b1aabe0-d0f9-4fe1-9b59-16ab7bdced57",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method withColumn in module pyspark.sql.dataframe:\n",
      "\n",
      "withColumn(colName, col) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Returns a new :class:`DataFrame` by adding a column or replacing the\n",
      "    existing column that has the same name.\n",
      "    \n",
      "    The column expression must be an expression over this :class:`DataFrame`; attempting to add\n",
      "    a column from some other :class:`DataFrame` will raise an error.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    colName : str\n",
      "        string, name of the new column.\n",
      "    col : :class:`Column`\n",
      "        a :class:`Column` expression for the new column.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    This method introduces a projection internally. Therefore, calling it multiple\n",
      "    times, for instance, via loops in order to add multiple columns can generate big\n",
      "    plans which can cause performance issues and even `StackOverflowException`.\n",
      "    To avoid this, use :func:`select` with the multiple columns at once.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.withColumn('age2', df.age + 2).collect()\n",
      "    [Row(age=2, name='Alice', age2=4), Row(age=5, name='Bob', age2=7)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(users_df.withColumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "250cb2be-95eb-4156-9b88-943f00f6b270",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "000153fd-3af8-453f-a98b-b1eba7fe95dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+--------+\n",
      "| id|first_name|   last_name|      fn|\n",
      "+---+----------+------------+--------+\n",
      "|  1|    Corrie|Van den Oord|  Corrie|\n",
      "|  2|  Nikolaus|     Brewitt|Nikolaus|\n",
      "|  3|    Orelie|      Penney|  Orelie|\n",
      "|  4|     Ashby|    Maddocks|   Ashby|\n",
      "|  5|      Kurt|        Rome|    Kurt|\n",
      "+---+----------+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df. \\\n",
    "    select('id', 'first_name', 'last_name'). \\\n",
    "    withColumn('fn', users_df['first_name']). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f1e6ffc2-210f-47de-90cf-493fb588d556",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "* Add another column by name `course_count` where it contain number of courses the user is enrolled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "53488a1b-2bb1-4a3c-8857-3fe713e09401",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|courses|\n",
      "+---+-------+\n",
      "|  1| [1, 2]|\n",
      "|  2|    [3]|\n",
      "|  3| [2, 4]|\n",
      "|  4|     []|\n",
      "|  5|     []|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select('id', 'courses'). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fb2797db-f9e9-430d-8e3a-5e4efb2b9d32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'), ('courses', 'array<bigint>')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df.select('id', 'courses'). \\\n",
    "    dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ff66a362-7459-45c8-b283-63b6b11acbfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "87afded1-d1ec-4f88-8831-e25cdfdaaad4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------------+\n",
      "| id|courses|course_count|\n",
      "+---+-------+------------+\n",
      "|  1| [1, 2]|           2|\n",
      "|  2|    [3]|           1|\n",
      "|  3| [2, 4]|           2|\n",
      "|  4|     []|           0|\n",
      "|  5|     []|           0|\n",
      "+---+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_df.select('id', 'courses'). \\\n",
    "    withColumn('course_count', size('courses')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d87141da-386a-417c-b117-92b3188bad36",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "",
       "errorTraceType": null,
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11 Naming derived columns using withColumn",
   "notebookOrigID": 456917195749024,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
